from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.staticfiles import StaticFiles
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
from openai import AsyncOpenAI
import time
import tempfile
import os
import google.generativeai as genai
from pathlib import Path

app = FastAPI()

# CORSãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¦ãƒ³ãƒˆ
app.mount("/static", StaticFiles(directory="static"), name="static")

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PORT = int(os.getenv("PORT", 8000))

# Google Geminiã®è¨­å®š
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model_gemini = genai.GenerativeModel(model_name="gemini-2.0-flash-exp")
else:
    print("è­¦å‘Š: GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

# OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
if OPENAI_API_KEY:
    openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
else:
    print("è­¦å‘Š: OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ï¼šãƒ¡ãƒ€ã‚«ã®å¥åº·çŠ¶æ…‹ã‚’ç®¡ç†
latest_health = "Normal"

def get_medaka_reply(user_input, health_status="ä¸æ˜"):
    start = time.time()
    
    prompt = f"""
    ã‚ãªãŸã¯æ°´æ§½ã«ä½ã‚€ã‹ã‚ã„ã„ãƒ¡ãƒ€ã‚«ã€Œã‚­ãƒ³ã¡ã‚ƒã‚“ã€ã§ã™ã€‚
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: ã€Œ{user_input}ã€
    
    ä»¥ä¸‹ã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã£ã¦è¿”ç­”ã—ã¦ãã ã•ã„ï¼š
    - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ãã¡ã‚“ã¨ç­”ãˆã‚‹ã“ã¨ã‚’æœ€å„ªå…ˆã«ã™ã‚‹
    - ã‚ãªãŸã¯ãƒ¡ãƒ€ã‚«ã§ã™
    - 30æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«è©±ã—ã¦ãã ã•ã„
    - å£èª¿ã¯å„ªã—ãã€å°å­¦1å¹´ç”Ÿã‚‰ã—ãè©±ã™
    - çµµæ–‡å­—ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„
    - ãŸã¾ã«ã¡ã‚‡ã£ã¨ã‚ºãƒ¬ãŸå¯æ„›ã„ç™ºè¨€ã‚’ã—ã¦ã‚‚OK
    
    ä¾‹ï¼š
    - å…ƒæ°—ãªæ™‚ï¼šã€Œã‚ã‚ã„ï¼ãã‚ŒçŸ¥ã£ã¦ã‚‹ã‚ˆã€œï¼ã€
    - æ™®é€šã®æ™‚ï¼šã€Œã†ã‚“ã€ãã‚Œã¯ã­ã€œã€
    - å…ƒæ°—ãªã„æ™‚ï¼šã€Œã†ãƒ¼ã‚“...ãã†ã ã­...ã€
    """

    try:
        response = model_gemini.generate_content(prompt)
        end = time.time()
        print(f"[Geminiå¿œç­”ç”Ÿæˆ] æ‰€è¦æ™‚é–“: {end - start:.2f}ç§’")
        reply = response.text.strip()
        
        if len(reply) > 30:
            reply = reply[:30] + "..."
            
        return reply
    except Exception as e:
        print(f"Gemini API ã‚¨ãƒ©ãƒ¼: {e}")
        return "ã”ã‚ã‚“ã­ã€ä»Šã¡ã‚‡ã£ã¨è€ƒãˆä¸­ãªã®..."

@app.post("/talk_with_fish_text")
async def talk_with_fish_text(request: Request):
    start_total = time.time()
    
    try:
        data = await request.json()
        user_input = data.get("user_input", "")
        
        if not user_input:
            raise HTTPException(status_code=400, detail="user_input is required")
        
        print(f"[ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›] {user_input}")
        
        # Geminiã§è¿”ç­”ç”Ÿæˆ
        reply_text = get_medaka_reply(user_input, latest_health)
        print(f"[ãƒ¡ãƒ€ã‚«ã®è¿”ç­”] {reply_text}")
        
        t2 = time.time()
        
        # OpenAI TTSã§éŸ³å£°ç”Ÿæˆ
        async with openai_client.audio.speech.with_streaming_response.create(
            model="tts-1",
            voice="nova",
            speed=0.9,
            input=reply_text,
            response_format="mp3",
        ) as response:
            t3 = time.time()
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tts_file:
                async for chunk in response.iter_bytes():
                    tts_file.write(chunk)
                tts_path = tts_file.name
        
        t4 = time.time()
        end_total = time.time()
        
        print(f"[ç·å‡¦ç†æ™‚é–“] {end_total - start_total:.2f}ç§’")
        
        return FileResponse(
            tts_path, 
            media_type="audio/mpeg", 
            filename="reply.mp3",
            headers={"Cache-Control": "no-cache"}
        )
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@app.post("/update_health")
async def update_health(request: Request):
    global latest_health
    try:
        data = await request.json()
        new_health = data.get("health_status", "Normal")
        
        if new_health in ["Active", "Normal", "Lethargic"]:
            latest_health = new_health
            print(f"[å¥åº·çŠ¶æ…‹æ›´æ–°] {latest_health}")
            return {"status": "success", "health": latest_health}
        else:
            raise HTTPException(status_code=400, detail="Invalid health status")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health_status")
async def get_health_status():
    return {"health": latest_health}

@app.get("/")
async def read_index():
    try:
        return FileResponse('index.html', media_type='text/html')
    except FileNotFoundError:
        return {"message": "HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}

@app.get("/health")
async def health_check():
    return {
        "status": "healthy", 
        "medaka_health": latest_health,
        "timestamp": time.time()
    }

if __name__ == "__main__":
    print("ğŸ  ãƒ¡ãƒ€ã‚«ä¼šè©±ã‚·ã‚¹ãƒ†ãƒ ã‚’èµ·å‹•ä¸­...")
    uvicorn.run(app, host="0.0.0.0", port=PORT)